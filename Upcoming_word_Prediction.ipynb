{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Upcoming word Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_p1k9j9AQ_v"
      },
      "source": [
        "Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbNRUgX-GADH"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsDx_bDYAWle"
      },
      "source": [
        "Upload File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "kpeUfy-THSCN",
        "outputId": "3f2fcd96-bd6a-4936-e3fa-5fe3726424a8"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12311c71-1e07-448b-9781-2bd2fc557572\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12311c71-1e07-448b-9781-2bd2fc557572\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving next_word_predictor.txt to next_word_predictor.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzSl5VkHsU-"
      },
      "source": [
        "file= open(\"next_word_predictor.txt\",'r',encoding=\"utf-8\")\n",
        "lines=[]\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "data =\"\"\n",
        "for i in lines:\n",
        "  data =' '.join(lines)\n",
        "\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmUfoTfXAdXj"
      },
      "source": [
        "Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "zCupUTgzKtei",
        "outputId": "b312d8e1-5120-419e-bd49-66d2ffc6b741"
      },
      "source": [
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Project Gutenberg eBook of Narrative of the Life of Frederick Douglass, by Frederick Douglass This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where '"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ovkHAzKK5bj",
        "outputId": "e9b2f737-f0f8-496b-eff7-1e1e7945ed39"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 68, 60, 392, 2, 346, 2, 1, 117, 2, 205, 206, 21, 205, 206]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6UVWhEoK_tR",
        "outputId": "39ceb1c8-8d6c-43d4-a955-e686a9438507"
      },
      "source": [
        "len(sequence_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44357"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsA8hFqLLF4k",
        "outputId": "124a7550-671d-46a2-f0e4-b52dd171e786"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6-su6JNLJxd",
        "outputId": "7477407e-b3ca-429f-aedf-5cb2c3d276ef"
      },
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "    \n",
        "print(\"The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Length of sequences are:  44354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,  68,  60, 392],\n",
              "       [ 68,  60, 392,   2],\n",
              "       [ 60, 392,   2, 346],\n",
              "       [392,   2, 346,   2],\n",
              "       [  2, 346,   2,   1],\n",
              "       [346,   2,   1, 117],\n",
              "       [  2,   1, 117,   2],\n",
              "       [  1, 117,   2, 205],\n",
              "       [117,   2, 205, 206],\n",
              "       [  2, 205, 206,  21]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l4p-bAhLM1K"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "    \n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ZDiXLrLSOl",
        "outputId": "4cb5c1d2-6083-4f51-923e-5195066a32c1"
      },
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[  1  68  60]\n",
            " [ 68  60 392]\n",
            " [ 60 392   2]\n",
            " [392   2 346]\n",
            " [  2 346   2]\n",
            " [346   2   1]\n",
            " [  2   1 117]\n",
            " [  1 117   2]\n",
            " [117   2 205]\n",
            " [  2 205 206]]\n",
            "Response:  [392   2 346   2   1 117   2 205 206  21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjbuIgF7LV3_",
        "outputId": "275174ab-d543-4ee1-c64d-bd032cb24098"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRgKXT4EAnPm"
      },
      "source": [
        "LSTM Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1hI99BLaPr"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnvUsaQSLeHF",
        "outputId": "00f95729-9cf3-467d-a8ee-df8dd36e2fbe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3, 10)             56120     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 3, 1000)           4044000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5612)              5617612   \n",
            "=================================================================\n",
            "Total params: 18,722,732\n",
            "Trainable params: 18,722,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdXV3IVOLiCo",
        "outputId": "132cd0bd-0f1d-484f-faec-440b50190d3d"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=36, batch_size=64, callbacks=[checkpoint])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/36\n",
            "694/694 [==============================] - 66s 33ms/step - loss: 5.2627 - accuracy: 0.1446\n",
            "\n",
            "Epoch 00001: loss improved from inf to 5.26267, saving model to next_words.h5\n",
            "Epoch 2/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 5.0035 - accuracy: 0.1527\n",
            "\n",
            "Epoch 00002: loss improved from 5.26267 to 5.00355, saving model to next_words.h5\n",
            "Epoch 3/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 4.7786 - accuracy: 0.1613\n",
            "\n",
            "Epoch 00003: loss improved from 5.00355 to 4.77862, saving model to next_words.h5\n",
            "Epoch 4/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 4.5529 - accuracy: 0.1699\n",
            "\n",
            "Epoch 00004: loss improved from 4.77862 to 4.55288, saving model to next_words.h5\n",
            "Epoch 5/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 4.3262 - accuracy: 0.1800\n",
            "\n",
            "Epoch 00005: loss improved from 4.55288 to 4.32623, saving model to next_words.h5\n",
            "Epoch 6/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 4.0994 - accuracy: 0.1930\n",
            "\n",
            "Epoch 00006: loss improved from 4.32623 to 4.09941, saving model to next_words.h5\n",
            "Epoch 7/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 3.8662 - accuracy: 0.2100\n",
            "\n",
            "Epoch 00007: loss improved from 4.09941 to 3.86624, saving model to next_words.h5\n",
            "Epoch 8/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 3.6340 - accuracy: 0.2304\n",
            "\n",
            "Epoch 00008: loss improved from 3.86624 to 3.63405, saving model to next_words.h5\n",
            "Epoch 9/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 3.4111 - accuracy: 0.2574\n",
            "\n",
            "Epoch 00009: loss improved from 3.63405 to 3.41106, saving model to next_words.h5\n",
            "Epoch 10/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 3.1780 - accuracy: 0.2874\n",
            "\n",
            "Epoch 00010: loss improved from 3.41106 to 3.17800, saving model to next_words.h5\n",
            "Epoch 11/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 2.9618 - accuracy: 0.3218\n",
            "\n",
            "Epoch 00011: loss improved from 3.17800 to 2.96179, saving model to next_words.h5\n",
            "Epoch 12/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 2.7495 - accuracy: 0.3548\n",
            "\n",
            "Epoch 00012: loss improved from 2.96179 to 2.74955, saving model to next_words.h5\n",
            "Epoch 13/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 2.5510 - accuracy: 0.3903\n",
            "\n",
            "Epoch 00013: loss improved from 2.74955 to 2.55096, saving model to next_words.h5\n",
            "Epoch 14/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 2.3419 - accuracy: 0.4299\n",
            "\n",
            "Epoch 00014: loss improved from 2.55096 to 2.34192, saving model to next_words.h5\n",
            "Epoch 15/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 2.1479 - accuracy: 0.4682\n",
            "\n",
            "Epoch 00015: loss improved from 2.34192 to 2.14794, saving model to next_words.h5\n",
            "Epoch 16/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.9654 - accuracy: 0.5055\n",
            "\n",
            "Epoch 00016: loss improved from 2.14794 to 1.96538, saving model to next_words.h5\n",
            "Epoch 17/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.7860 - accuracy: 0.5425\n",
            "\n",
            "Epoch 00017: loss improved from 1.96538 to 1.78602, saving model to next_words.h5\n",
            "Epoch 18/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.6144 - accuracy: 0.5810\n",
            "\n",
            "Epoch 00018: loss improved from 1.78602 to 1.61437, saving model to next_words.h5\n",
            "Epoch 19/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.4633 - accuracy: 0.6145\n",
            "\n",
            "Epoch 00019: loss improved from 1.61437 to 1.46329, saving model to next_words.h5\n",
            "Epoch 20/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.3165 - accuracy: 0.6489\n",
            "\n",
            "Epoch 00020: loss improved from 1.46329 to 1.31654, saving model to next_words.h5\n",
            "Epoch 21/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.1778 - accuracy: 0.6823\n",
            "\n",
            "Epoch 00021: loss improved from 1.31654 to 1.17781, saving model to next_words.h5\n",
            "Epoch 22/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 1.0609 - accuracy: 0.7095\n",
            "\n",
            "Epoch 00022: loss improved from 1.17781 to 1.06092, saving model to next_words.h5\n",
            "Epoch 23/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.9643 - accuracy: 0.7368\n",
            "\n",
            "Epoch 00023: loss improved from 1.06092 to 0.96427, saving model to next_words.h5\n",
            "Epoch 24/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.8642 - accuracy: 0.7616\n",
            "\n",
            "Epoch 00024: loss improved from 0.96427 to 0.86422, saving model to next_words.h5\n",
            "Epoch 25/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.7892 - accuracy: 0.7833\n",
            "\n",
            "Epoch 00025: loss improved from 0.86422 to 0.78923, saving model to next_words.h5\n",
            "Epoch 26/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.7246 - accuracy: 0.7988\n",
            "\n",
            "Epoch 00026: loss improved from 0.78923 to 0.72460, saving model to next_words.h5\n",
            "Epoch 27/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.6615 - accuracy: 0.8162\n",
            "\n",
            "Epoch 00027: loss improved from 0.72460 to 0.66147, saving model to next_words.h5\n",
            "Epoch 28/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.6071 - accuracy: 0.8299\n",
            "\n",
            "Epoch 00028: loss improved from 0.66147 to 0.60708, saving model to next_words.h5\n",
            "Epoch 29/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.5718 - accuracy: 0.8400\n",
            "\n",
            "Epoch 00029: loss improved from 0.60708 to 0.57177, saving model to next_words.h5\n",
            "Epoch 30/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.5505 - accuracy: 0.8426\n",
            "\n",
            "Epoch 00030: loss improved from 0.57177 to 0.55052, saving model to next_words.h5\n",
            "Epoch 31/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.5096 - accuracy: 0.8528\n",
            "\n",
            "Epoch 00031: loss improved from 0.55052 to 0.50963, saving model to next_words.h5\n",
            "Epoch 32/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.4927 - accuracy: 0.8586\n",
            "\n",
            "Epoch 00032: loss improved from 0.50963 to 0.49273, saving model to next_words.h5\n",
            "Epoch 33/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.4848 - accuracy: 0.8578\n",
            "\n",
            "Epoch 00033: loss improved from 0.49273 to 0.48481, saving model to next_words.h5\n",
            "Epoch 34/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.4448 - accuracy: 0.8688\n",
            "\n",
            "Epoch 00034: loss improved from 0.48481 to 0.44476, saving model to next_words.h5\n",
            "Epoch 35/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.4252 - accuracy: 0.8737\n",
            "\n",
            "Epoch 00035: loss improved from 0.44476 to 0.42518, saving model to next_words.h5\n",
            "Epoch 36/36\n",
            "694/694 [==============================] - 23s 33ms/step - loss: 0.4269 - accuracy: 0.8725\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.42518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81163a8750>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNrUCEzLogR"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hXXANW3AObP"
      },
      "source": [
        "Upcoming Word Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFHBl5ScL3EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040a8bcb-dda0-4d1c-9259-29e7965b5a02"
      },
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: who have been melted\n",
            "['have', 'been', 'melted']\n",
            "to\n",
            "Enter your line: I shall never\n",
            "['I', 'shall', 'never']\n",
            "forget\n",
            "Enter your line: 0\n",
            "Execution completed.....\n"
          ]
        }
      ]
    }
  ]
}